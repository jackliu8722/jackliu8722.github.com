
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>EM算法 - 精神兵的 Blog</title>
  <meta name="author" content="jackliu">

  
  <meta name="description" content="1 简介 一直对EM算法有一种莫明的喜欢感，觉得它非常的神奇，其思想也非常的让人深思，给我的感觉就是一种美。 EM算法是最大期望算法(Exception-maximization algorithm)的简称。它是一种迭代算法，用于求含有隐变量的概率模型参数的极大似然估计。 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://jackliu8722.github.com/blog/2013/09/08/emsuan-fa/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="精神兵的 Blog" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$$$','$$$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">精神兵的 Blog</a></h1>
  
    <h2>领袖与跟风者的区别就在于创新——乔布斯</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:jackliu8722.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">博客首页</a></li>
  <li><a href="/blog/archives">博客列表</a></li>
  <li><a href="/blog/categories/ml/">机器学习</a></li>
  <li><a href="/blog/categories/distributed/">分布式</a></li>
  <li><a href="/blog/categories/arch/">架构</a></li>
  <li><a href="/blog/categories/db/">存储</a></li>
  <li><a href="/blog/categories/java/">Java</a></li>
  <li><a href="/blog/categories/python/">Python</a></li>
  <li><a href="/blog/categories/linux/">Linux</a></li>
  <li><a href="/blog/categories/math/">数学</a></li>
  <li><a href="/blog/categories/blockchain/">区块链</a></li>
  <li><a href="/blog/categories/others/">其它</a></li>
  <li><a href="/about/">关于</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">EM算法</h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-08T20:30:00+08:00" pubdate data-updated="true">2013年09月08日</time>
        
      </p>
    
  </header>


<div class="entry-content"><h2>1 简介</h2>

<p>一直对EM算法有一种莫明的喜欢感，觉得它非常的神奇，其思想也非常的让人深思，给我的感觉就是一种美。</p>

<p>EM算法是最大期望算法(Exception-maximization algorithm)的简称。它是一种迭代算法，用于求含有隐变量的概率模型参数的极大似然估计。</p>

<p>EM算法经过两个步骤交替进行计算，从而求得概率模型的极大似然估计：</p>

<ol>
<li><p>第一步计算期望，也就是E，利用对隐变量的现在估计值，计算模型的极大似然估计值。</p></li>
<li><p>第二步是最大化过程，也就是M。该过程在第一步基础上计算模型到达极大值时参数的值。</p></li>
</ol>


<h2>2 EM算法的推导</h2>

<h4>2.1 算法的引入</h4>

<p>假设我们记n个观测样本为
\[x_1,x_2,x_3,…,x_k,…,x_n\]
<strong>注意:</strong>一般我们假设各样本之间满足独立同分布(independent and identically distributed, i.i.d)。</p>

<p>观测样本即为观测变量，可将所有的观测变量记为<strong>X</strong>。相应的，观测变量对应的隐变量为
\[z_1,z_2,z_3,…,z_k,…z_n\]
同样的，假设隐变量之间满足独立同分布，记所有的隐变量为<strong>Z</strong>。观测变量与隐变量的联合分布为 <strong>$$ P(X,Z |\theta )$$</strong></p>

<p>其中， $$$\theta$$$是模型的参数。</p>

<p>一般地，我们可以将观测变量X称为不完全数据，将(X,Z)称为完全数据(complete-data)。我们的目标是最大化$$$P(X|\theta)$$$，而
\[P(X|\theta)= \sum_{Z}P(X,Z|\theta) \]</p>

<p>假设Z是离散的（如果Z是连续的，可以用积分代替求和）。</p>

<p>在最大化$$$P(X|\theta)$$$的时候，如果不存在隐变量，我们可以直接通过最大似然估计求解模型的参数$$$\theta$$$，由于隐变量Z的存在，求解模型参数的最优值就变得比较困难了。但是求解完全数据的最大似然函数$$$P(X,Z|\theta)$$$的最优解是比较容易的。</p>

<h4>2.2 算法的推导</h4>

<p>从2.1节我们已经知道，我们的目标是最大化$$$P(X|\theta)$$$，而我们可以做如下的一些推导。
\[ P(X|\theta)={P(X,Z|\theta) \over P(Z|X,\theta) }\]
两边取对数
\[ \ln P(X|\theta)=\ln {P(X,Z|\theta) \over P(Z|X,\theta)}\]
即可得到
\[ \ln P(X|\theta)=\ln P(X,Z|\theta)  - \ln P(Z|X,\theta)\]
假设有分布$$$\ln q(Z)$$$，则有
\[ \ln P(X|\theta)=\ln P(X,Z|\theta)  - \ln q(Z) + \ln q(Z) - \ln P(Z|X,\theta)\]</p>

<p>\[ \ln P(X|\theta)=(\ln P(X,Z|\theta) - \ln q(Z)) - (\ln P(Z|X,\theta)-\ln q(Z))\]</p>

<p>\[ \ln P(X|\theta)={\ln {P(X,Z|\theta) \over q(Z)}} - {\ln {P(Z|X,\theta) \over q(Z)}}\]
等式两边同乘以$$$q(Z)$$$，并对Z求积分(Z是连续随机变量)或者求和(Z是离散随机变量)，假设Z是连接的，则有
\[ \int_{Z} q(Z)\ln P(X|\theta) \,dZ = \int_{Z}q(Z)({\ln {P(X,Z|\theta) \over q(Z)}} - {\ln {P(Z|X,\theta) \over q(Z)}})\,dZ \]</p>

<p>\[ \int_{Z} q(Z)\ln P(X|\theta) \,dZ = {\int_{Z}q(Z){\ln {P(X,Z|\theta) \over q(Z)}}\,dZ} - {\int_{Z}q(Z)\ln {P(Z|X,\theta) \over q(Z)}}\,dZ \]</p>

<p>\[ \int_{Z} q(Z)\ln P(X|\theta) \,dZ = {\int_{Z}q(Z){\ln {P(X,Z|\theta) \over q(Z)}}\,dZ} + {\int_{Z}q(Z)\ln {q(Z) \over P(Z|X,\theta)}}\,dZ \]</p>

<p>由于Z和X之间相互独立，因此有
\[ \int_{Z}q(Z)\ln P(X|\theta)\,dZ = \int_{Z}q(Z)\,dZ \ln(X|\theta) \]
而$$$\int_{Z}q(Z)\,dZ = 1$$$，因此有 $$$\int_{Z}q(Z)q(Z)\ln P(X|\theta)\,dZ = ln(X|\theta)$$$，则有
\[ \ln P(X|\theta) = {\int_{Z}q(Z){\ln {P(X,Z|\theta) \over q(Z)}}\,dZ} + {\int_{Z}q(Z)\ln {q(Z) \over P(Z|X,\theta)}}\,dZ \]
记
\[ \zeta(q,\theta)={\int_{Z}q(Z){\ln {P(X,Z|\theta) \over q(Z)}}\,dZ}\]</p>

<p>\[ KL(q||p) = {\int_{Z}q(Z)\ln {q(Z) \over P(Z|X,\theta)}}\,dZ\]
KL是KL距离，也就是Kullback-Leibler差异（Kullback-Leibler Divergence）的简称，也叫做相对熵（Relative Entropy）。它衡量的是相同事件空间里的两个概率分布的差异情况。其物理意义是：在相同事件空间里，概率分布P(x)的事件空间，若用概率分布Q(x)编码时，平均每个基本事件（符号）编码长度增加了多少比特。KL的一个重要性质是 $$$KL(P|Q)\ge0$$$，当且仅当$$$P=Q$$$时，等号成立。</p>

<p>则有\[ \ln P(X|\theta) = \zeta(q,\theta) + KL(q||p) \]</p>

<p>由于\[ KL(q||p) \ge 0 \]
则有\[ \ln P(X|\theta) \ge \zeta(q,\theta) \]
也就是说$$$\zeta(q,\theta)$$$是$$$\ln P(X|\theta)$$$的下界。</p>

<p>EM算法可以通过不断提高下界$$$\zeta(q,\theta)$$$的值来逼近$$$\ln P(X|\theta)$$$的最大值，因此EM算法分为以下两步通过迭代的方法求$$$\ln P(X|\theta)$$$的最大似然估计值：</p>

<ol>
<li>在E步中，假设当前的参数为$$$\theta ^{old}$$$，并固定参数$$$\theta ^{old}$$$不变，则最大化下界$$$\zeta(q,\theta ^{old})$$$与$$$q(Z)$$$有关，并且$$$\ln P(X|\theta ^{old})$$$与$$$q(Z)$$$不相关，因此，要使$$$\zeta(q,\theta)$$$最大，等价于使$$$KL(q||p)$$$最小，由KL距离的性质可知 $$$q(Z)=P(Z|X,\theta ^{old})$$$</li>
<li>在M步中，固定$$$q(Z)$$$，最大化下界$$$\zeta(q,\theta)$$$与$$$\theta$$$有关，即寻找一个新的值$$$\theta ^{new}$$$使得$$$\zeta(q,\theta ^{new})$$$最大。$$$\theta ^{new}$$$会使下界$$$\zeta(q,\theta)$$$的值增大（除非已经达到最大值），并且也一定会使似然函数的值增大，因为在M步中，分布q(Z)使用的是参数$$$\theta ^{old}$$$而不是参数$$$\theta ^{new}$$$，则$$$q(Z)\ne P(Z|X,\theta ^{new}) $$$，从而$$$KL(q||p)> 0$$$，因此，似然函数增大部分的值比仅提高下界多带来的增幅大，从而能够逼近$$$\ln P(X|\theta)$$$的最大似然估计。</li>
</ol>


<p>在最大化$$$\zeta(q,\theta)$$$的过程中，由 $$$q(Z)=P(Z|X,\theta ^{old})$$$ 可知
\[ \zeta(q,\theta)={\int_{Z}P(Z|X,\theta ^{old}){\ln {P(X,Z|\theta) \over P(Z|X,\theta ^{old})}}\,dZ}\]
\[ \zeta(q,\theta)={\int_{Z}P(Z|X,\theta ^{old})\ln P(X,Z|\theta)}\,dZ - {\int_{Z}P(Z|X,\theta ^{old})\ln P(Z|X,\theta ^{old})}\,dZ\]
由于$$${\int_{Z}P(Z|X,\theta ^{old})\ln P(Z|X,\theta ^{old})}\,dZ$$$为常数，则有
\[ \zeta(q,\theta)={\int_{Z}P(Z|X,\theta ^{old})\ln P(X,Z|\theta)}\,dZ + const \]
因此最大化$$$\zeta(q,\theta)$$$等价于最大化$$${\int_{Z}P(Z|X,\theta ^{old})\ln P(X,Z|\theta)}\,dZ$$$</p>

<h2>3 说明</h2>

<p>关于EM算法，作以下几点说明：</p>

<ol>
<li>参数的初始值可以任意选择，但需要注意的是EM算法对参数的初值是敏感的。</li>
<li>EM算法中，E步是就函数$$${\int_{Z}P(Z|X,\theta ^{old})\ln P(X,Z|\theta)}\,dZ$$$，我们可以定义Q函数 \[ Q(\theta,\theta ^{k}) = {\int_{Z}P(Z|X,\theta ^{k})\ln P(X,Z|\theta)}\,dZ\] 表示完全数据的对数似然函数$$$\ln P(Y,Z|\theta)$$$关于给定观测数据$$$Y$$$和给定参数$$$$\theta ^{k}$$$的条件下对未观测数据$$$Z$$$的条件概率分布$$$P(Z|X,\theta ^{k})$$$的期望，因此，Q函数也可以写成如下形式\[ Q(\theta,\theta ^{k}) = E_{Z}[\ln P(X,Z|\theta)|X,\theta ^{k}]\] 变元$$$\theta$$$表示需要极大化的参数，变元$$$\theta ^{k}$$$表示参数当前的估计值。</li>
<li>EM算法中，M步是在求$$$Q(\theta,\theta ^{k})$$$的极大化，完成一次迭代$$$\theta ^{k} \rightarrow\theta ^{k+1}$$$。</li>
<li>EM算法迭代的停止条件一般为，给定较小的正数$$$\varepsilon _{1},\varepsilon _{2}$$$，若满足 \[\parallel \theta ^{k+1} - \theta ^{k} \parallel &lt; \varepsilon _{1}\] 或 \[\parallel Q(\theta ^{k+1},\theta ^{k}) - Q(\theta ^{k},\theta ^{k}) \parallel &lt; \varepsilon_{2}\] 则停止迭代。每次迭代其实是在求Q函数及其极大化。</li>
</ol>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">jackliu</span></span>

      








  


<time datetime="2013-09-08T20:30:00+08:00" pubdate data-updated="true">2013年09月08日</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/ml/'>机器学习</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
  
</div>
<hr style="border-bottom:1px dotted #bdbabd;height:1px;border-top:0px;border-left:0px;border-right:0px;" />


 
      <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
	<span class="jiathis_txt">分享到：</span>
	<a class="jiathis_button_tools_1"></a>
	<a class="jiathis_button_tools_2"></a>
	<a class="jiathis_button_tools_3"></a>
	<a class="jiathis_button_tools_4"></a>
	<a href="http://www.jiathis.com/share?uid=1836686" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript">
var jiathis_config = {data_track_clickback:'true'};
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1355984157367920" charset="utf-8"></script>
<!-- JiaThis Button END -->
<!-- UJian Button BEGIN -->
	<div class="ujian-hook"></div>
	<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js"></script>
<!-- UJian Button END -->

  

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2013/09/05/octopressde-an-zhuang-yu-pei-zhi/" title="Previous Post: Octopress的安装与配置">&laquo; Octopress的安装与配置</a>
      
      
        <a class="basic-alignment right" href="/blog/2013/09/18/linuxchang-yong-ming-ling-ji-jin/" title="Next Post: linux常用命令集锦">linux常用命令集锦 &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    
<section>
<h1>博客分类</h1>
<ul>
  <li><a href='/blog/categories/java/'>Java (2)</a></li>
  <li><a href='/blog/categories/linux/'>Linux (2)</a></li>
  <li><a href='/blog/categories/Python/'>Python (1)</a></li>
  <li><a href='/blog/categories/others/'>其它 (3)</a></li>
  <li><a href='/blog/categories/distributed/'>分布式 (9)</a></li>
  <li><a href='/blog/categories/blockchain/'>区块链 (2)</a></li>
  <li><a href='/blog/categories/db/'>存储 (1)</a></li>
  <li><a href='/blog/categories/ml/'>机器学习 (2)</a></li>
  <li><a href='/blog/categories/arch/'>架构 (2)</a></li>
</ul>
</section>

<section>
  <h1>最近博文</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/11/29/fabric-consensus-analysis-2/">fabric共识机制分析2</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/10/13/fabric-consensus-analysis-1/">fabric共识机制分析1</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/01/06/thrift-network-package-introduce/">Thrift网络请求包格式详解</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/11/14/innodb-01-mysql-install/">Innodb源码分析(1)--Mysql环境的搭建</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/05/04/wei-xin-hong-bao-yuan-li/">微信红包原理</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>新浪微博</h1>
  <ul id="weibo">
    <li>
      <iframe 
        width="100%" 
        height="550" 
        class="share_self" 
        frameborder="0" 
        scrolling="no" 
        src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=2&ptype=1&speed=0&skin=1&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=1835292725&verifier=d90a04d3&dpc=1">
      </iframe>
    </li>
  </ul>
</section>






  
</aside>

<section>
<h1>发表评论</h1>
 <div class="ds-thread"></div>
  <script type="text/javascript">
  var duoshuoQuery = {short_name:"yangdd"};
  (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.src = 'http://static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>

</section>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - jackliu -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
